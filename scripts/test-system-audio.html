<!doctype html>
<html>
  <head>
    <title>Audio Capture Test</title>
    <style>
      body {
        font-family: Arial, sans-serif;
        padding: 20px;
        max-width: 800px;
        margin: 0 auto;
      }
      button {
        padding: 15px 25px;
        margin: 10px;
        font-size: 16px;
        border: none;
        border-radius: 5px;
        cursor: pointer;
      }
      .start {
        background-color: #28a745;
        color: white;
      }
      .stop {
        background-color: #dc3545;
        color: white;
      }
      .test {
        background-color: #007bff;
        color: white;
      }
      .status {
        margin: 15px 0;
        padding: 15px;
        border-radius: 5px;
        font-weight: bold;
      }
      .success {
        background-color: #d4edda;
        color: #155724;
      }
      .error {
        background-color: #f8d7da;
        color: #721c24;
      }
      .info {
        background-color: #d1ecf1;
        color: #0c5460;
      }
      .log {
        background-color: #f8f9fa;
        border: 1px solid #dee2e6;
        border-radius: 5px;
        padding: 15px;
        max-height: 400px;
        overflow-y: auto;
        font-family: monospace;
        font-size: 12px;
      }
      .log div {
        margin: 2px 0;
      }
      audio {
        width: 100%;
        margin: 15px 0;
      }
    </style>
  </head>
  <body>
    <h1>ğŸ™ï¸ Audio Capture Test</h1>

    <div>
      <button id="testBtn" class="test">ğŸ§ª Test getUserMedia</button>
      <button id="startBtn" class="start">ğŸ™ï¸ Start Audio Recording</button>
      <button id="stopBtn" class="stop" disabled>ğŸ›‘ Stop Recording</button>
      <button id="clearBtn">ğŸ—‘ï¸ Clear Log</button>
    </div>

    <div id="status" class="status info">Ready to test audio capture</div>

    <div id="audioPlayer" style="display: none">
      <h3>ğŸµ Recorded Audio:</h3>
      <audio id="audioElement" controls></audio>
      <button id="downloadBtn" class="test">ğŸ’¾ Download Audio</button>
    </div>

    <div id="log" class="log"></div>

    <script>
      let mediaRecorder = null;
      let audioChunks = [];
      let isRecording = false;
      let recordedBlob = null;
      let currentStream = null;

      function log(message, type = "info") {
        const logDiv = document.getElementById("log");
        const timestamp = new Date().toLocaleTimeString();
        const logEntry = document.createElement("div");
        logEntry.className = type;
        logEntry.innerHTML = `[${timestamp}] ${message}`;
        logDiv.appendChild(logEntry);
        logDiv.scrollTop = logDiv.scrollHeight;
        console.log(message);
      }

      function updateStatus(message, type = "info") {
        const statusDiv = document.getElementById("status");
        statusDiv.className = `status ${type}`;
        statusDiv.textContent = message;
      }

      function clearLog() {
        document.getElementById("log").innerHTML = "";
      }

      async function testGetUserMedia() {
        try {
          log("ğŸ§ª Testing getUserMedia availability...");
          updateStatus("Testing getUserMedia...", "info");

          // Check if getUserMedia is available
          if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
            throw new Error("getUserMedia not available");
          }

          log("âœ… getUserMedia is available");
          log("ğŸ“‹ Navigator:", !!navigator);
          log("ğŸ“‹ MediaDevices:", !!navigator.mediaDevices);
          log("ğŸ“‹ getUserMedia:", !!navigator.mediaDevices.getUserMedia);
          log("ğŸ“‹ User Agent:", navigator.userAgent);

          // Test with audio constraints
          log("ğŸ§ª Testing audio capture...");
          const testStream = await navigator.mediaDevices.getUserMedia({
            audio: {
              sampleRate: 16000,
              channelCount: 1,
              echoCancellation: false,
              noiseSuppression: false,
              autoGainControl: false,
            },
          });

          log("âœ… Audio-only capture test successful!");
          log(
            "ğŸ“Š Stream tracks:",
            testStream
              .getTracks()
              .map((t) => t.kind)
              .join(", ")
          );
          log(
            "ğŸ“Š Track details:",
            JSON.stringify(
              testStream.getTracks().map((t) => ({
                kind: t.kind,
                enabled: t.enabled,
                muted: t.muted,
                readyState: t.readyState,
              })),
              null,
              2
            )
          );

          // Stop the test stream
          testStream.getTracks().forEach((track) => track.stop());
          log("ğŸ›‘ Test stream stopped");

          updateStatus("getDisplayMedia test successful!", "success");
        } catch (error) {
          log(`âŒ getDisplayMedia test failed: ${error.message}`, "error");
          log(`âŒ Error name: ${error.name}`, "error");
          log(`âŒ Full error:`, "error");
          console.error(error);
          updateStatus(`Test failed: ${error.message}`, "error");
        }
      }

      async function startRecording() {
        try {
          log("ğŸ™ï¸ Starting system audio recording...");
          updateStatus("Requesting system audio access...", "info");

          // Check if getUserMedia is available
          if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
            throw new Error("getUserMedia not available");
          }

          log("âœ… getUserMedia available, requesting stream...");

          // Use the same approach as test-browser-audio.html - getUserMedia for audio
          // This is more reliable than getDisplayMedia on Windows
          log("ğŸ™ï¸ Attempting audio capture using getUserMedia...");

          const stream = await navigator.mediaDevices.getUserMedia({
            audio: {
              sampleRate: 16000,
              channelCount: 1,
              echoCancellation: false,
              noiseSuppression: false,
              autoGainControl: false,
            },
          });

          log("âœ… Audio capture succeeded using getUserMedia");

          currentStream = stream;
          log("âœ… Audio stream obtained");
          log("ğŸ“Š Stream ID:", stream.id);
          log("ğŸ“Š Stream active:", stream.active);
          log(
            "ğŸ“Š Tracks:",
            stream
              .getTracks()
              .map((t) => t.kind)
              .join(", ")
          );

          // Check if we actually have audio tracks
          const audioTracks = stream.getAudioTracks();
          const videoTracks = stream.getVideoTracks();

          log("ğŸ“Š Audio tracks count:", audioTracks.length);
          log("ğŸ“Š Video tracks count:", videoTracks.length);

          if (audioTracks.length === 0) {
            throw new Error(
              "No audio tracks found in the stream. Audio capture is not working."
            );
          }

          // Log detailed track information
          audioTracks.forEach((track, index) => {
            log(`ğŸ“Š Audio track ${index}:`, {
              id: track.id,
              enabled: track.enabled,
              muted: track.muted,
              readyState: track.readyState,
              label: track.label,
            });
          });

          // Create MediaRecorder with simple approach
          mediaRecorder = new MediaRecorder(stream);
          log(
            `âœ… MediaRecorder created with MIME type: ${mediaRecorder.mimeType}`
          );
          log(`âœ… MediaRecorder state: ${mediaRecorder.state}`);

          // Set up event handlers
          audioChunks = [];

          mediaRecorder.ondataavailable = (event) => {
            if (event.data.size > 0) {
              audioChunks.push(event.data);
              log(`ğŸ“¦ Audio chunk received: ${event.data.size} bytes`);
            } else {
              log("âš ï¸ Empty audio chunk received");
            }
          };

          mediaRecorder.onstart = () => {
            log("ğŸ™ï¸ MediaRecorder started");
            log(`âœ… MediaRecorder state: ${mediaRecorder.state}`);
            isRecording = true;
            document.getElementById("startBtn").disabled = true;
            document.getElementById("stopBtn").disabled = false;
            updateStatus("Recording audio...", "success");
          };

          mediaRecorder.onstop = async () => {
            log("ğŸ›‘ MediaRecorder stopped");
            log(`ğŸ“Š Total chunks: ${audioChunks.length}`);
            log(
              `ğŸ“Š Total size: ${audioChunks.reduce((sum, chunk) => sum + chunk.size, 0)} bytes`
            );

            if (audioChunks.length > 0) {
              recordedBlob = new Blob(audioChunks, { type: "audio/webm" });
              log(`âœ… Created audio blob: ${recordedBlob.size} bytes`);

              // Create audio URL for playback
              const audioUrl = URL.createObjectURL(recordedBlob);
              const audioElement = document.getElementById("audioElement");
              audioElement.src = audioUrl;
              document.getElementById("audioPlayer").style.display = "block";

              updateStatus(
                `Recording completed! ${recordedBlob.size} bytes`,
                "success"
              );
            } else {
              log("âŒ No audio chunks received", "error");
              updateStatus("No audio data recorded", "error");
            }

            isRecording = false;
            document.getElementById("startBtn").disabled = false;
            document.getElementById("stopBtn").disabled = true;

            // Stop all tracks
            if (currentStream) {
              currentStream.getTracks().forEach((track) => {
                track.stop();
                log(`ğŸ›‘ Stopped track: ${track.kind}`);
              });
              currentStream = null;
            }
          };

          mediaRecorder.onerror = (event) => {
            log(`âŒ MediaRecorder error: ${event.error}`, "error");
            updateStatus(`Recording error: ${event.error}`, "error");
          };

          // Start recording
          mediaRecorder.start(1000); // 1-second timeslice
          log("ğŸ™ï¸ Started recording with 1-second timeslice");
        } catch (error) {
          log(`âŒ Failed to start recording: ${error.message}`, "error");
          log(`âŒ Error name: ${error.name}`, "error");
          log(`âŒ Full error:`, "error");
          console.error(error);
          updateStatus(`Recording failed: ${error.message}`, "error");
        }
      }

      function stopRecording() {
        if (mediaRecorder && isRecording) {
          log("ï¿½ï¿½ Stopping recording...");
          mediaRecorder.stop();
        }
      }

      function downloadAudio() {
        if (recordedBlob) {
          const url = URL.createObjectURL(recordedBlob);
          const a = document.createElement("a");
          a.href = url;
          a.download = `audio_${new Date().toISOString().slice(0, 19).replace(/:/g, "-")}.webm`;
          document.body.appendChild(a);
          a.click();
          document.body.removeChild(a);
          URL.revokeObjectURL(url);
          log("ğŸ’¾ Download started");
        }
      }

      // Event listeners
      document
        .getElementById("testBtn")
        .addEventListener("click", testGetUserMedia);
      document
        .getElementById("startBtn")
        .addEventListener("click", startRecording);
      document
        .getElementById("stopBtn")
        .addEventListener("click", stopRecording);
      document.getElementById("clearBtn").addEventListener("click", clearLog);
      document
        .getElementById("downloadBtn")
        .addEventListener("click", downloadAudio);

      log("ğŸš€ Audio capture test ready");
      log("ğŸ“‹ Browser: " + navigator.userAgent);
      log(
        "ğŸ“‹ MediaDevices available: " +
          !!(navigator.mediaDevices && navigator.mediaDevices.getUserMedia)
      );
      log("ğŸ“‹ MediaRecorder available: " + !!window.MediaRecorder);
      updateStatus("Ready to test audio capture", "info");
    </script>
  </body>
</html>
